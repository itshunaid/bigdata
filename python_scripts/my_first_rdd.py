# -*- coding: utf-8 -*-
"""my_first_rdd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t6OXlFBAnjnFgnXWKVhg4HhtHWpr0K_6
"""

!wget https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz
!tar -xvf spark-3.2.0-bin-hadoop3.2.tgz
import os
os.environ["JAVA_HOME"]= "/usr/lib/jvm/java-11-openjdk-amd64"
os.environ["SPARK_HOME"]="/content/spark-3.2.0-bin-hadoop3.2"
!pip install findspark
import findspark
findspark.init()

from pyspark.sql import SparkSession
from pyspark import SparkContext

spark = SparkSession.builder.master("local[*]").getOrCreate()

sc=spark.sparkContext

my_rdd=sc.parallelize([20,40,50,60,70])

type(my_rdd)

my_rdd.collect()

!wget https://raw.githubusercontent.com/itshunaid/bigdata/main/retailstore.csv

my_csv_rdd =  sc.textFile('retailstore.csv')

my_csv_rdd.collect()

type(my_csv_rdd)

my_csv_rdd.first()

my_csv_rdd.take(3)

for line in my_csv_rdd.collect():
 print(line)